{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from selectors import DefaultSelector, EVENT_READ, EVENT_WRITE\n",
    "import socket\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "selector = DefaultSelector()\n",
    "class Fetcher:\n",
    "    def __init__(self, host, url, level=0):\n",
    "        self.response = b''  # Empty array of bytes.\n",
    "        self.host = host\n",
    "        self.url = url\n",
    "        self.sock = None\n",
    "        self.level = level\n",
    "        \n",
    "    # Method on Fetcher class.\n",
    "    def fetch(self):\n",
    "        self.sock = socket.socket()\n",
    "        self.sock.setblocking(False)\n",
    "        try:\n",
    "            self.sock.connect((self.host, 80))\n",
    "        except BlockingIOError:\n",
    "            pass\n",
    "\n",
    "        # Register next callback.\n",
    "        selector.register(self.sock.fileno(),\n",
    "                          EVENT_WRITE,\n",
    "                          self.connected)\n",
    "\n",
    "    def connected(self, key, mask):\n",
    "        print('connected!', flush=True)\n",
    "        selector.unregister(key.fd)\n",
    "        request = 'GET {} HTTP/1.0\\r\\nHost: {}\\r\\n\\r\\n'.format(self.url, self.host)\n",
    "        self.sock.send(request.encode('ascii'))\n",
    "\n",
    "        # Register the next callback.\n",
    "        selector.register(key.fd,\n",
    "                          EVENT_READ,\n",
    "                          self.read_response)\n",
    "        \n",
    "    def read_response(self, key, mask):\n",
    "        global stopped, urls_todo, seen_urls\n",
    "        urls_todo = set(['/'])\n",
    "        seen_urls = set(['/'])\n",
    "            \n",
    "        chunk = self.sock.recv(128)  # USUALLY 4k chunk size, here small\n",
    "        if chunk:\n",
    "            print(\"read chunk\", flush=True)\n",
    "            self.response += chunk\n",
    "        else:\n",
    "            print(\"all read\", flush=True)\n",
    "            selector.unregister(key.fd)  # Done reading.\n",
    "            \n",
    "            if (self.level < 1):\n",
    "                links = self.parse_links()\n",
    "                if links:\n",
    "                    urls_todo.add(seen_urls.difference(links))  # Add unseen urls\n",
    "                    \n",
    "                    for url in urls_todo:\n",
    "                        parsed = urlparse(url)\n",
    "                        host = parsed.hostname\n",
    "                        url = parsed.path\n",
    "                        fetcher = Fetcher(host, url, self.level+1)\n",
    "                        fetcher.fetch()\n",
    "\n",
    "                    seen_urls.update(links)\n",
    "                    urls_todo.remove(self.url)\n",
    "                    if not urls_todo:\n",
    "                        stopped = True\n",
    "                else:\n",
    "                    stopped = True     \n",
    "            else:\n",
    "                stopped = True\n",
    "    \n",
    "    def parse_links(self):\n",
    "        links = set()\n",
    "        soup = BeautifulSoup(self.response, 'html.parser')\n",
    "        for link in soup.find_all('a'):\n",
    "            links.add(link.get('href'))\n",
    "        \n",
    "        \n",
    "stopped = False\n",
    "\n",
    "def loop():\n",
    "    while not stopped:\n",
    "        events = selector.select()\n",
    "        for event_key, event_mask in events:\n",
    "            callback = event_key.data\n",
    "            callback(event_key, event_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connected!\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "all read\n"
     ]
    }
   ],
   "source": [
    "fetcher = Fetcher('xkcd.com', '/353/')\n",
    "fetcher.fetch()\n",
    "loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
